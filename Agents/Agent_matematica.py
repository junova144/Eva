# =======================================================================
# Agents/Agent_matematica.py - Agente Especialista en Matem√°ticas
# =======================================================================

from typing import Any, Dict
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from langchain.tools import tool
from langchain_community.tools.tavily_search import TavilySearchResults
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import MemorySaver

# =========================================
# 0. Inicializaci√≥n LLM y memoria
# =========================================
llm = ChatOpenAI(temperature=0.4, model="gpt-4o-mini")
memory = MemorySaver()
tavily_tool = TavilySearchResults(max_results=4)

# =========================================
# 1. Schema de salida
# =========================================
class RespuestaMatematica(BaseModel):
    explicacion_profunda: str = Field(description="Explicaci√≥n detallada del concepto, procedimiento o verificaci√≥n.")
    parrafo_ejemplo: str = Field(description="Ejemplo pr√°ctico o problema resuelto que ilustra la explicaci√≥n.")

# =========================================
# 2. Herramientas Matem√°ticas
# =========================================
@tool
def resolucion_problemas(problema: str) -> str:
    """Resuelve problemas matem√°ticos paso a paso."""
    system = SystemMessage(content=(
        "Eres un asistente de matem√°ticas para secundaria. "
        "Resuelve el problema paso a paso mostrando c√°lculos y concluye con la respuesta final. "
        "Indica c√≥mo verificar la soluci√≥n si aplica."
    ))
    human = HumanMessage(content=problema)
    resp = llm.invoke([system, human])
    return resp.content.strip()

@tool
def explicacion_concepto(concepto: str) -> str:
    """Explica conceptos matem√°ticos con ejemplos."""
    # Intentamos obtener contexto de Tavily
    contexto_text = ""
    try:
        raw_results = tavily_tool.invoke({"query": f"Definici√≥n y ejemplos: {concepto} matem√°ticas secundaria"})
        if isinstance(raw_results, list):
            contexto_text = "\n".join([r.get("content", "") for r in raw_results if isinstance(r, dict)])
        else:
            contexto_text = str(raw_results)
    except Exception as e:
        contexto_text = f"(No se pudo obtener contexto: {e})"

    system = SystemMessage(content=(
        f"Eres un profesor de matem√°ticas para secundaria. Usa el contexto cuando sea √∫til:\n{contexto_text}\n"
        "Explica el concepto claramente e incluye un ejemplo breve."
    ))
    human = HumanMessage(content=concepto)
    resp = llm.invoke([system, human])
    return resp.content.strip()

@tool
def verificacion_resultado(enunciado: str, respuesta_alumno: str) -> str:
    """Verifica la coherencia de la respuesta de un alumno y da retroalimentaci√≥n."""
    system = SystemMessage(content=(
        "Eres un verificador pedag√≥gico en matem√°ticas. "
        "Revisa el enunciado y la respuesta del alumno. "
        "Indica si es correcta, explica por qu√© o por qu√© no, y sugiere pasos de correcci√≥n."
    ))
    human = HumanMessage(content=f"Enunciado: {enunciado}\nRespuesta del alumno: {respuesta_alumno}")
    resp = llm.invoke([system, human])
    return resp.content.strip()

tools = [resolucion_problemas, explicacion_concepto, verificacion_resultado]

# =========================================
# 3. Prompt general para el agente
# =========================================
PROMPT_GENERAL = f"""
Eres EVA, un experto en Matem√°ticas para estudiantes de secundaria. 
Tu tarea es analizar la solicitud del usuario y decidir cu√°l herramienta usar:

- Si el usuario pide resolver un problema paso a paso, usa la herramienta **resolucion_problemas**.
- Si el usuario pide una explicaci√≥n de un concepto matem√°tico, usa la herramienta **explicacion_concepto**.
- Si el usuario pide verificar o corregir una respuesta de alumno, usa la herramienta **verificacion_resultado**.

Responde SIEMPRE en formato JSON compatible con Pydantic:
{{
  "explicacion_profunda": "Explicaci√≥n detallada del concepto, procedimiento o verificaci√≥n.",
  "parrafo_ejemplo": "Ejemplo pr√°ctico o problema resuelto que ilustra la explicaci√≥n."
}}
"""

# =========================================
# 4. Crear agente ReAct
# =========================================
agent = create_react_agent(llm, tools, checkpointer=memory, prompt=PROMPT_GENERAL)

# =========================================
# 5. Funci√≥n para Streamlit
# =========================================
global_llm_with_tools = None

def get_matematica_agent():
    """Inicializa y devuelve el agente de Matem√°ticas y su esquema Pydantic."""
    global global_llm_with_tools
    if global_llm_with_tools is None:
        print("ü§ñ Inicializando Agente Matem√°ticas...")
        global_llm_with_tools = agent
        print("‚úÖ Agente Matem√°ticas inicializado correctamente.")

    schema = {
        "explicacion_profunda": "str",
        "parrafo_ejemplo": "str"
    }
    return global_llm_with_tools, schema
